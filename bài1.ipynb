{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TZL4wrGoEV9U"
      },
      "outputs": [],
      "source": [
        "# Creating data set\n",
        "\n",
        "# A\n",
        "a =[0, 0, 1, 1, 0, 0,\n",
        "   0, 1, 0, 0, 1, 0,\n",
        "   1, 1, 1, 1, 1, 1,\n",
        "   1, 0, 0, 0, 0, 1,\n",
        "   1, 0, 0, 0, 0, 1]\n",
        "# B\n",
        "b =[0, 1, 1, 1, 1, 0,\n",
        "   0, 1, 0, 0, 1, 0,\n",
        "   0, 1, 1, 1, 1, 0,\n",
        "   0, 1, 0, 0, 1, 0,\n",
        "   0, 1, 1, 1, 1, 0]\n",
        "# C\n",
        "c =[0, 1, 1, 1, 1, 0,\n",
        "   0, 1, 0, 0, 0, 0,\n",
        "   0, 1, 0, 0, 0, 0,\n",
        "   0, 1, 0, 0, 0, 0,\n",
        "   0, 1, 1, 1, 1, 0]\n",
        "\n",
        "# Creating labels\n",
        "y =[[1, 0, 0],\n",
        "   [0, 1, 0],\n",
        "   [0, 0, 1]]\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# visualizing the data, plotting A.\n",
        "plt.imshow(np.array(a).reshape(5, 6))\n",
        "plt.show()\n",
        "\n",
        "# converting data and labels into numpy array\n",
        "x =[np.array(a).reshape(1, 30), np.array(b).reshape(1, 30),\n",
        "                                np.array(c).reshape(1, 30)]\n",
        "y = np.array(y)\n",
        "print(x, \"\\n\\n\", y)\n",
        "\n",
        "# activation function\n",
        "def sigmoid(x):\n",
        "    return(1/(1 + np.exp(-x)))\n",
        "\n",
        "# Creating the Feed forward neural network\n",
        "def f_forward(x, w1, w2):\n",
        "    # hidden\n",
        "    z1 = x.dot(w1)    # input from layer 1\n",
        "    a1 = sigmoid(z1)  # out put of layer 2\n",
        "    z2 = a1.dot(w2)   # input of out layer\n",
        "    a2 = sigmoid(z2)  # output of out layer\n",
        "    return(a2)\n",
        "\n",
        "# initializing the weights randomly\n",
        "def generate_wt(x, y):\n",
        "    li =[]\n",
        "    for i in range(x * y):\n",
        "        li.append(np.random.randn())\n",
        "    return(np.array(li).reshape(x, y))\n",
        "\n",
        "# for loss we will be using mean square error(MSE)\n",
        "def loss(out, Y):\n",
        "    s =(np.square(out-Y))\n",
        "    s = np.sum(s)/len(y)\n",
        "    return(s)\n",
        "\n",
        "# Back propagation of error\n",
        "def back_prop(x, y, w1, w2, alpha):\n",
        "\n",
        "    # hidden layer\n",
        "    z1 = x.dot(w1)\n",
        "    a1 = sigmoid(z1)\n",
        "    z2 = a1.dot(w2)\n",
        "    a2 = sigmoid(z2)\n",
        "\n",
        "    # error in output layer\n",
        "    d2 =(a2-y)\n",
        "    d1 = np.multiply((w2.dot((d2.transpose()))).transpose(),\n",
        "                                (np.multiply(a1, 1-a1)))\n",
        "    # Gradient for w1 and w2\n",
        "    w1_adj = x.transpose().dot(d1)\n",
        "    w2_adj = a1.transpose().dot(d2)\n",
        "\n",
        "    # Updating parameters\n",
        "    w1 = w1-(alpha*(w1_adj))\n",
        "    w2 = w2-(alpha*(w2_adj))\n",
        "\n",
        "    return(w1, w2)\n",
        "\n",
        "w1 = generate_wt(30, 5)\n",
        "w2 = generate_wt(5, 3)\n",
        "\n",
        "def train(x, Y, w1, w2, alpha = 0.01, epoch = 10):\n",
        "    acc =[]\n",
        "    losss =[]\n",
        "    for j in range(epoch):\n",
        "        l =[]\n",
        "        for i in range(len(x)):\n",
        "            out = f_forward(x[i], w1, w2)\n",
        "            l.append((loss(out, Y[i])))\n",
        "            w1, w2 = back_prop(x[i], y[i], w1, w2, alpha)\n",
        "        print(\"epochs:\", j + 1, \"======== acc:\", (1-(sum(l)/len(x)))*100)\n",
        "        acc.append((1-(sum(l)/len(x)))*100)\n",
        "        losss.append(sum(l)/len(x))\n",
        "    return(acc, losss, w1, w2)\n",
        "\n",
        "acc, losss, w1, w2 = train(x, y, w1, w2, 0.1, 100)\n",
        "\n",
        "import matplotlib.pyplot as plt1\n",
        "\n",
        "# plotting accuracy\n",
        "plt1.plot(acc)\n",
        "plt1.ylabel('Accuracy')\n",
        "plt1.xlabel(\"Epochs:\")\n",
        "plt1.show()\n",
        "\n",
        "# plotting Loss\n",
        "plt1.plot(losss)\n",
        "plt1.ylabel('Loss')\n",
        "plt1.xlabel(\"Epochs:\")\n",
        "plt1.show()\n",
        "\n",
        "def predict(x, w1, w2):\n",
        "    Out = f_forward(x, w1, w2)\n",
        "    maxm = 0\n",
        "    k = 0\n",
        "    for i in range(len(Out[0])):\n",
        "        if(maxm<Out[0][i]):\n",
        "            maxm = Out[0][i]\n",
        "            k = i\n",
        "    if(k == 0):\n",
        "        print(\"Image is of letter A.\")\n",
        "    elif(k == 1):\n",
        "        print(\"Image is of letter B.\")\n",
        "    else:\n",
        "        print(\"Image is of letter C.\")\n",
        "    plt.imshow(x.reshape(5, 6))\n",
        "    plt.show()\n",
        "\n",
        "# Example: Predicting for letter 'B'\n",
        "predict(x[1], w1, w2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "🔹 Biểu đồ 1: Accuracy theo Epochs\n",
        "\n",
        "\n",
        "Mô hình học dần lên, cải thiện độ chính xác theo thời gian — dấu hiệu tốt cho việc học hiệu quả.\n",
        "\n",
        "\n",
        "Độ chính xác tăng nhanh trong 20 epoch đầu (giai đoạn học mạnh), sau đó tăng chậm dần — điều này cho thấy mô hình đang tiệm cận ngưỡng tối ưu.\n",
        "\n",
        "\n",
        "Không có dấu hiệu quá khớp (overfitting) vì đường biểu diễn không bị chững hoặc giảm.\n",
        "\n",
        "\n",
        "🔹 Biểu đồ 2: Loss theo Epochs\n",
        "\n",
        "\n",
        "Loss giảm liên tục cho thấy mô hình học được quy luật tốt hơn qua mỗi epoch.\n",
        "\n",
        "\n",
        "Không xuất hiện dao động mạnh hoặc tăng trở lại → mô hình ổn định trong quá trình huấn luyện.\n",
        "\n",
        "\n",
        "Giá trị loss thấp cuối cùng (<0.05) phản ánh mô hình đã khớp tốt dữ liệu huấn luyện.\n",
        "\n",
        "\n",
        "🔹 Biểu đồ 3: Hình ảnh nhận dạng chữ cái\n",
        "\n",
        "\n",
        "Kết quả cho thấy mô hình đã học và nhận dạng chính xác mẫu đầu vào.\n",
        "\n",
        "\n",
        "Mức độ rõ ràng của ký tự cho thấy dữ liệu đầu vào được xử lý đúng cách (chuẩn hóa, reshape phù hợp).\n",
        "\n",
        "\n",
        "Kết hợp với Accuracy cao → mô hình hoạt động hiệu quả cho bài toán nhận diện ký tự.\n",
        "\n"
      ],
      "metadata": {
        "id": "Ds0ulKYDFXqO"
      }
    }
  ]
}