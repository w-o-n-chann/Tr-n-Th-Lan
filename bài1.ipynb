{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TZL4wrGoEV9U"
      },
      "outputs": [],
      "source": [
        "# Creating data set\n",
        "\n",
        "# A\n",
        "a =[0, 0, 1, 1, 0, 0,\n",
        "   0, 1, 0, 0, 1, 0,\n",
        "   1, 1, 1, 1, 1, 1,\n",
        "   1, 0, 0, 0, 0, 1,\n",
        "   1, 0, 0, 0, 0, 1]\n",
        "# B\n",
        "b =[0, 1, 1, 1, 1, 0,\n",
        "   0, 1, 0, 0, 1, 0,\n",
        "   0, 1, 1, 1, 1, 0,\n",
        "   0, 1, 0, 0, 1, 0,\n",
        "   0, 1, 1, 1, 1, 0]\n",
        "# C\n",
        "c =[0, 1, 1, 1, 1, 0,\n",
        "   0, 1, 0, 0, 0, 0,\n",
        "   0, 1, 0, 0, 0, 0,\n",
        "   0, 1, 0, 0, 0, 0,\n",
        "   0, 1, 1, 1, 1, 0]\n",
        "\n",
        "# Creating labels\n",
        "y =[[1, 0, 0],\n",
        "   [0, 1, 0],\n",
        "   [0, 0, 1]]\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# visualizing the data, plotting A.\n",
        "plt.imshow(np.array(a).reshape(5, 6))\n",
        "plt.show()\n",
        "\n",
        "# converting data and labels into numpy array\n",
        "x =[np.array(a).reshape(1, 30), np.array(b).reshape(1, 30),\n",
        "                                np.array(c).reshape(1, 30)]\n",
        "y = np.array(y)\n",
        "print(x, \"\\n\\n\", y)\n",
        "\n",
        "# activation function\n",
        "def sigmoid(x):\n",
        "    return(1/(1 + np.exp(-x)))\n",
        "\n",
        "# Creating the Feed forward neural network\n",
        "def f_forward(x, w1, w2):\n",
        "    # hidden\n",
        "    z1 = x.dot(w1)    # input from layer 1\n",
        "    a1 = sigmoid(z1)  # out put of layer 2\n",
        "    z2 = a1.dot(w2)   # input of out layer\n",
        "    a2 = sigmoid(z2)  # output of out layer\n",
        "    return(a2)\n",
        "\n",
        "# initializing the weights randomly\n",
        "def generate_wt(x, y):\n",
        "    li =[]\n",
        "    for i in range(x * y):\n",
        "        li.append(np.random.randn())\n",
        "    return(np.array(li).reshape(x, y))\n",
        "\n",
        "# for loss we will be using mean square error(MSE)\n",
        "def loss(out, Y):\n",
        "    s =(np.square(out-Y))\n",
        "    s = np.sum(s)/len(y)\n",
        "    return(s)\n",
        "\n",
        "# Back propagation of error\n",
        "def back_prop(x, y, w1, w2, alpha):\n",
        "\n",
        "    # hidden layer\n",
        "    z1 = x.dot(w1)\n",
        "    a1 = sigmoid(z1)\n",
        "    z2 = a1.dot(w2)\n",
        "    a2 = sigmoid(z2)\n",
        "\n",
        "    # error in output layer\n",
        "    d2 =(a2-y)\n",
        "    d1 = np.multiply((w2.dot((d2.transpose()))).transpose(),\n",
        "                                (np.multiply(a1, 1-a1)))\n",
        "    # Gradient for w1 and w2\n",
        "    w1_adj = x.transpose().dot(d1)\n",
        "    w2_adj = a1.transpose().dot(d2)\n",
        "\n",
        "    # Updating parameters\n",
        "    w1 = w1-(alpha*(w1_adj))\n",
        "    w2 = w2-(alpha*(w2_adj))\n",
        "\n",
        "    return(w1, w2)\n",
        "\n",
        "w1 = generate_wt(30, 5)\n",
        "w2 = generate_wt(5, 3)\n",
        "\n",
        "def train(x, Y, w1, w2, alpha = 0.01, epoch = 10):\n",
        "    acc =[]\n",
        "    losss =[]\n",
        "    for j in range(epoch):\n",
        "        l =[]\n",
        "        for i in range(len(x)):\n",
        "            out = f_forward(x[i], w1, w2)\n",
        "            l.append((loss(out, Y[i])))\n",
        "            w1, w2 = back_prop(x[i], y[i], w1, w2, alpha)\n",
        "        print(\"epochs:\", j + 1, \"======== acc:\", (1-(sum(l)/len(x)))*100)\n",
        "        acc.append((1-(sum(l)/len(x)))*100)\n",
        "        losss.append(sum(l)/len(x))\n",
        "    return(acc, losss, w1, w2)\n",
        "\n",
        "acc, losss, w1, w2 = train(x, y, w1, w2, 0.1, 100)\n",
        "\n",
        "import matplotlib.pyplot as plt1\n",
        "\n",
        "# plotting accuracy\n",
        "plt1.plot(acc)\n",
        "plt1.ylabel('Accuracy')\n",
        "plt1.xlabel(\"Epochs:\")\n",
        "plt1.show()\n",
        "\n",
        "# plotting Loss\n",
        "plt1.plot(losss)\n",
        "plt1.ylabel('Loss')\n",
        "plt1.xlabel(\"Epochs:\")\n",
        "plt1.show()\n",
        "\n",
        "def predict(x, w1, w2):\n",
        "    Out = f_forward(x, w1, w2)\n",
        "    maxm = 0\n",
        "    k = 0\n",
        "    for i in range(len(Out[0])):\n",
        "        if(maxm<Out[0][i]):\n",
        "            maxm = Out[0][i]\n",
        "            k = i\n",
        "    if(k == 0):\n",
        "        print(\"Image is of letter A.\")\n",
        "    elif(k == 1):\n",
        "        print(\"Image is of letter B.\")\n",
        "    else:\n",
        "        print(\"Image is of letter C.\")\n",
        "    plt.imshow(x.reshape(5, 6))\n",
        "    plt.show()\n",
        "\n",
        "# Example: Predicting for letter 'B'\n",
        "predict(x[1], w1, w2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ”¹ Biá»ƒu Ä‘á»“ 1: Accuracy theo Epochs\n",
        "\n",
        "\n",
        "MÃ´ hÃ¬nh há»c dáº§n lÃªn, cáº£i thiá»‡n Ä‘á»™ chÃ­nh xÃ¡c theo thá»i gian â€” dáº¥u hiá»‡u tá»‘t cho viá»‡c há»c hiá»‡u quáº£.\n",
        "\n",
        "\n",
        "Äá»™ chÃ­nh xÃ¡c tÄƒng nhanh trong 20 epoch Ä‘áº§u (giai Ä‘oáº¡n há»c máº¡nh), sau Ä‘Ã³ tÄƒng cháº­m dáº§n â€” Ä‘iá»u nÃ y cho tháº¥y mÃ´ hÃ¬nh Ä‘ang tiá»‡m cáº­n ngÆ°á»¡ng tá»‘i Æ°u.\n",
        "\n",
        "\n",
        "KhÃ´ng cÃ³ dáº¥u hiá»‡u quÃ¡ khá»›p (overfitting) vÃ¬ Ä‘Æ°á»ng biá»ƒu diá»…n khÃ´ng bá»‹ chá»¯ng hoáº·c giáº£m.\n",
        "\n",
        "\n",
        "ðŸ”¹ Biá»ƒu Ä‘á»“ 2: Loss theo Epochs\n",
        "\n",
        "\n",
        "Loss giáº£m liÃªn tá»¥c cho tháº¥y mÃ´ hÃ¬nh há»c Ä‘Æ°á»£c quy luáº­t tá»‘t hÆ¡n qua má»—i epoch.\n",
        "\n",
        "\n",
        "KhÃ´ng xuáº¥t hiá»‡n dao Ä‘á»™ng máº¡nh hoáº·c tÄƒng trá»Ÿ láº¡i â†’ mÃ´ hÃ¬nh á»•n Ä‘á»‹nh trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n.\n",
        "\n",
        "\n",
        "GiÃ¡ trá»‹ loss tháº¥p cuá»‘i cÃ¹ng (<0.05) pháº£n Ã¡nh mÃ´ hÃ¬nh Ä‘Ã£ khá»›p tá»‘t dá»¯ liá»‡u huáº¥n luyá»‡n.\n",
        "\n",
        "\n",
        "ðŸ”¹ Biá»ƒu Ä‘á»“ 3: HÃ¬nh áº£nh nháº­n dáº¡ng chá»¯ cÃ¡i\n",
        "\n",
        "\n",
        "Káº¿t quáº£ cho tháº¥y mÃ´ hÃ¬nh Ä‘Ã£ há»c vÃ  nháº­n dáº¡ng chÃ­nh xÃ¡c máº«u Ä‘áº§u vÃ o.\n",
        "\n",
        "\n",
        "Má»©c Ä‘á»™ rÃµ rÃ ng cá»§a kÃ½ tá»± cho tháº¥y dá»¯ liá»‡u Ä‘áº§u vÃ o Ä‘Æ°á»£c xá»­ lÃ½ Ä‘Ãºng cÃ¡ch (chuáº©n hÃ³a, reshape phÃ¹ há»£p).\n",
        "\n",
        "\n",
        "Káº¿t há»£p vá»›i Accuracy cao â†’ mÃ´ hÃ¬nh hoáº¡t Ä‘á»™ng hiá»‡u quáº£ cho bÃ i toÃ¡n nháº­n diá»‡n kÃ½ tá»±.\n",
        "\n"
      ],
      "metadata": {
        "id": "Ds0ulKYDFXqO"
      }
    }
  ]
}