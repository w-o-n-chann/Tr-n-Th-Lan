{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mi8aZaLYwnKM"
      },
      "outputs": [],
      "source": [
        "pip install opendatasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "# Upload the kaggle.json file that you downloaded from Kaggle\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "\n",
        "# Create the .kaggle directory and move the kaggle.json file there\n",
        "!mkdir ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "\n",
        "# Set permissions for the kaggle.json file\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# Set environment variables (optional, opendatasets might handle this)\n",
        "# You can verify if the authentication works after running the cell below\n",
        "# os.environ['KAGGLE_USERNAME'] = 'YOUR_KAGGLE_USERNAME'\n",
        "# os.environ['KAGGLE_KEY'] = 'YOUR_KAGGLE_KEY'"
      ],
      "metadata": {
        "id": "zQDfoBsGwrao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import opendatasets as od\n",
        "import os\n",
        "import random\n",
        "import argparse\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, classification_report\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import transforms, datasets, models\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Download the dataset\n",
        "dataset_url = 'https://www.kaggle.com/datasets/tawsifurrahman/tuberculosis-tb-chest-xray-dataset'\n",
        "od.download(dataset_url)"
      ],
      "metadata": {
        "id": "m8N9VnFiwuWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "# Define the data directory\n",
        "data_dir = './tuberculosis-tb-chest-xray-dataset/TB_Chest_Radiography_Database'\n",
        "# Define model checkpoints directory\n",
        "save_dir = \"checkpoints\""
      ],
      "metadata": {
        "id": "1fZL45CRwuZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------\n",
        "# Reproducibility & device\n",
        "# ---------------------------\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ---------------------------\n",
        "# Utility: metrics\n",
        "# ---------------------------\n",
        "def evaluate_model(model, loader):\n",
        "    model.eval()\n",
        "    y_true, y_probs, y_pred = [], [], []\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in loader:\n",
        "            xb = xb.to(device)\n",
        "            logits = model(xb).squeeze(-1).cpu()  # [batch]\n",
        "            probs = torch.sigmoid(logits).numpy()\n",
        "            preds = (probs >= 0.5).astype(int)\n",
        "            y_probs.extend(probs.tolist())\n",
        "            y_pred.extend(preds.tolist())\n",
        "            y_true.extend(yb.numpy().tolist())\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    try:\n",
        "        auc = roc_auc_score(y_true, y_probs)\n",
        "    except Exception:\n",
        "        auc = float(\"nan\")\n",
        "    cls_report = classification_report(y_true, y_pred, digits=4)\n",
        "    return acc, auc, cls_report"
      ],
      "metadata": {
        "id": "Sbq7aRJwwuba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(42)\n",
        "\n",
        "# transforms\n",
        "tf = transforms.Compose([\n",
        "      transforms.RandomResizedCrop((224,224)),\n",
        "      transforms.RandomHorizontalFlip(),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n",
        "  ])\n",
        "\n",
        "full_ds = datasets.ImageFolder(os.path.join(data_dir), transform=tf)\n",
        "# Store class_to_idx before splitting\n",
        "class_to_idx = full_ds.class_to_idx\n",
        "\n",
        "train_len = int(len(full_ds)*0.8)\n",
        "val_len = len(full_ds) - train_len\n",
        "train_ds, val_ds = random_split(full_ds, [train_len, val_len], generator=torch.Generator().manual_seed(42))\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=16, shuffle=True, num_workers=1)\n",
        "val_loader = DataLoader(val_ds, batch_size=16, shuffle=False, num_workers=1)"
      ],
      "metadata": {
        "id": "UX-YqtFMwuda"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model:resnet50 -> single logit output\n",
        "# using pretrained with weights='DEFAULT'\n",
        "# training from scratch with weights=None\n",
        "model = models.resnet50(weights=None)\n",
        "\n",
        "for param in model.parameters():\n",
        "      param.requires_grad = True  # fine-tune all (or set False to freeze)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 1)  # single logit\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=2)\n",
        "\n",
        "best_auc = 0.0\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "for epoch in range(2):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for xb, yb in tqdm(train_loader):\n",
        "        xb, yb = xb.to(device), yb.float().to(device)\n",
        "        logits = model(xb).squeeze(-1)  # [batch]\n",
        "        loss = criterion(logits, yb)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * xb.size(0)\n",
        "\n",
        "    train_loss = running_loss / len(train_loader.dataset)\n",
        "    val_acc, val_auc, val_report = evaluate_model(model, val_loader)\n",
        "    scheduler.step(val_loss := train_loss)  # or use val_auc etc\n",
        "    print(f\"[Epoch {epoch}] train_loss={train_loss:.4f} val_acc={val_acc:.4f} val_auc={val_auc:.4f} \\n {val_report}\")\n",
        "\n",
        "    if val_auc > best_auc:\n",
        "        best_auc = val_auc\n",
        "        ckpt = os.path.join(save_dir, \"tb_resnet50_best.pt\")\n",
        "        torch.save({\"model_state\": model.state_dict(), \"class_to_idx\": class_to_idx}, ckpt)\n",
        "        print(f\"  Saved best checkpoint to {ckpt}\")\n",
        "\n",
        "  # final eval\n",
        "test_acc, test_auc, test_report = evaluate_model(model, val_loader)\n",
        "print(f\"Final val acc={test_acc:.4f}, auc={test_auc:.4f} \\n {test_report}\")"
      ],
      "metadata": {
        "id": "xB6832hIwufV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}